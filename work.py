# -*- coding: utf-8 -*-
"""work.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ivlt4Aw1unpmP4pmfBMGOYFc6005jxre
"""

import pandas as pd
import numpy as np
from tqdm import tqdm
import datetime
import pickle
from datetime import datetime
from matplotlib import pyplot as plt
import graphviz
import os

# ML
from sklearn.experimental import enable_iterative_imputer  # noqa
from sklearn.decomposition import PCA
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import train_test_split, learning_curve, LearningCurveDisplay, LeaveOneOut, KFold, GridSearchCV, HalvingGridSearchCV
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.linear_model import LinearRegression, Lars, Ridge, Lasso
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score, mean_absolute_error, make_scorer, accuracy_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer
from sklearn.impute import KNNImputer, SimpleImputer, IterativeImputer
from sklearn.pipeline import Pipeline
from sklearn.manifold import TSNE
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, jaccard_score, average_precision_score
from sklearn.svm import SVC
from sklearn.inspection import permutation_importance
# import catboost
# from fedot.api.main import Fedot

# Stats
from scipy.stats import kstest, norm, spearmanr, pearsonr, chi2_contingency, chisquare, fisher_exact, barnard_exact
# import shap

# Setups
import warnings
warnings.filterwarnings("ignore")
generate_path = lambda m: f"model_{m.__class__.__name__}_{datetime.now().strftime('%d_%m_%y')}.pkl"
pd.options.display.float_format = '{:,.4f}'.format

"""# Data Load

Загружаем датасет Алмазова
"""

dataset_path = "/content/ALMAZOV_dataset.xlsx"
if (not os.path.exists(dataset_path)):
  !gdown 1mYU2x0NhbIhmuCYAKPSP3Q9345sPlAC1 -O ALMAZOV_dataset.xlsx
full_dataset = pd.read_excel(dataset_path)
dataset = full_dataset.copy()
dataset.head(5)

"""# Preproceeesing I

Было решено соединить методы лечения VBD STD в общую STD как метод лечения диетой
"""

dataset["Лечение"] = dataset["ID"].apply(lambda x: x[:3] if x[:3] != 'VBD' else 'STD')

"""есть выброс в НТГ"""

dataset.loc[(dataset["НТГ (нарушнгин толерантности к глюкозе)"]>0) & (dataset["НТГ (нарушнгин толерантности к глюкозе)"]<1) , "НТГ (нарушнгин толерантности к глюкозе)"] = 0

"""Выделим колонки, которые потребуются

- Насколько голодным ..., насколько сильно хотите есть и насколько сытым... как будто бы одно и тоже?
"""

medicines = {
    'STD': 'Диета',
    'SIB': 'Сибутрамин',
    'SAX': 'Лираглутид'
}

parameters_truncated = {
    'Глюкоза крови натощак ммоль/л (3,3-6,1) 0 мес': "Глюкоза",
    'Пол 0 - М, 1 - Ж': 'Пол',
    'Степень Ожир': 'Степень ожирения',
    'Инсулин пкмоль/л (17.80 - 173.00) перемножить 6,945 0 мес': 'Инсулин',
    'Индекс HOMA-IR (> 3) 0 мес': 'HOMA-IR',
    'Индекс HOMA-В (20×инсулин плазмы натощак (мкЕд/мл)/глюкозы плазмы натощак (ммоль/л)-3,5 ) 0 мес': 'HOMA-B',
    'ОХС ммоль/л (3,5-5,0) 0 мес': 'OXC',
    'Мочевая кислота ммоль/л (0.14 - 0.34) 0 мес': 'Мочевая Кислота',
    'ЛПВП ммоль/л (Ж >1.20, М>1.0) 0 мес': 'ЛПВП',
    'ЛПНП ммоль/л (<3.00) 0 мес': 'ЛПНП',
    'ТГ ммоль/л (<1.77) 0 мес': 'ТГ',
    'КА (0-3,5) 0 мес': 'КА',
    'С-РБ мг/л (0-6) 0 мес': 'СРБ',
    'Эмоциональное пищевое поведение В1.': 'Эмоциональное ПП',
    'Экстернальное пищевое поведение В1.': 'Экстернальное ПП',
    'Ограничительное (Диетическое) пищевое поведение В1.': 'Диетическое ПП',
    'Насколько голодным вы себя чувствуете? В1.': 'Голод',
    'Насколько сытым вы себя чувствуете? В1.': 'Сытость',
    'Насколько сильно вы хотите есть? В1.': 'Степень желания поесть',
    'Сколько пищи вы могли бы сейчас съесть? В1.': "Сколько может сьесть",
    'EQ-5 В1.': 'EQ-5',
    'Депрессия В1.': 'Депрессия',
    'Депрессия В1..1': 'Депрессия 2',
    'Тревога В1.': 'Тревога',
    'НТГ (нарушнгин толерантности к глюкозе)': 'НТГ',
    'МЗО=0/МНО=1 V3 (Мейгц)': 'МЗО/МНО_V3',
    'Стаж ожирения (1 - до 5 лет, 2 5-10 лет, 3 - более 10 лет': 'Стаж ожирения',
    'Фенотип ожирения - 0 - Центральное ожирение, 1 - Периферическое ожирение, более 0,9 у мужчин и 0,85 у женщин – центральное ожиренрие, менее периферическое': 'Фенотип ожирения',
    'Артериальная гипертензия': 'Артериальная гипертензия',
    'Дислипидемия': 'Дислипидемия'
}

parameters = [
    'Лечение',
    'Пол',
    'Возраст',
    'Рост',
    'Степень ожирения',
    'Стаж ожирения',
    'САД',
    'ДАД',
    'Пульс',
    'Глюкоза',
    'Инсулин',
    'HOMA-IR',
    'HOMA-B',
    'OXC',
    'Мочевая Кислота',
    'ЛПВП',
    'ЛПНП',
    'ТГ',
    'КА',
    'СРБ',
    'Вес 0 мес',
    'ОТ 0 мес',
    'ОБ 0 мес',
    'ОТ/ОБ 0 мес',
    'ИМТ 0 мес',
    'Эмоциональное ПП',
    'Экстернальное ПП',
    'Диетическое ПП',
    'Голод',
    'Сытость',
    'Степень желания поесть',
    'Сколько может сьесть',
    'EQ-5',
    'Депрессия',
    'Тревога',
    'НТГ',
    'Артериальная гипертензия',
    'Дислипидемия',
    'Фенотип ожирения',
    'МЗО/МНО_V3']


initial_columns = [
    'Вес 0 мес',
    'ОТ 0 мес',
    'ОБ 0 мес',
    'ОТ/ОБ 0 мес',
    'ИМТ 0 мес'
]

targets = [
    '% потери веса 3 мес',
    '% потери веса 6 мес',
    'Вес 3 мес',
    'Вес 6 мес',
    # 'ОТ 3 мес',
    # 'ОТ/ОБ 3 мес',
    # 'ОТ/ОБ 6 мес',
    # 'ОТ 6 мес',
    # 'ОБ 3 мес',
    # 'ОБ 6 мес',

]

medicine_keys = [
    "SIB",
    "STD",
    "SAX"
]

discret_params = ['НТГ',
                'Голод',
                'МЗО/МНО_V3',
                'Степень ожирения',
                'Тревога',
                'Пол',
                'Артериальная гипертензия',
                'Депрессия',
                'Сколько может сьесть',
                'Степень желания поесть',
                'Дислипидемия',
                'Экстернальное ПП',
                'Эмоциональное ПП',
                'Диетическое ПП',
                'Стаж ожирения',
                'Фенотип ожирения']

agroup_parameters = list(set(initial_columns+parameters+targets))
dataset.columns = list(map(lambda x: x.strip(), dataset.columns))
dataset.columns = list(map(lambda x: " ".join(x.split()), dataset.columns))
dataset.columns = list(map(lambda i: parameters_truncated[i] if i in parameters_truncated else i, dataset.columns))
dataset = dataset[agroup_parameters]

"""Восстанавливаем пропущенные данные и исправляем неточности, когда вес увеличился а процент > 0"""

dataset.loc[pd.isna(dataset['% потери веса 3 мес']) & ~pd.isna(dataset['Вес 3 мес']), '% потери веса 3 мес'] = round(
 (dataset.loc[pd.isna(dataset['% потери веса 3 мес']) & ~pd.isna(dataset['Вес 3 мес']), 'Вес 0 мес']
  - dataset.loc[pd.isna(dataset['% потери веса 3 мес']) & ~pd.isna(dataset['Вес 3 мес']), 'Вес 3 мес'])
  / dataset.loc[pd.isna(dataset['% потери веса 3 мес']) & ~pd.isna(dataset['Вес 3 мес']), 'Вес 0 мес'] * 100 , 1
)
dataset.loc[pd.isna(dataset['% потери веса 6 мес']) & ~pd.isna(dataset['Вес 6 мес']), '% потери веса 6 мес'] = round (
 (dataset.loc[pd.isna(dataset['% потери веса 6 мес']) & ~pd.isna(dataset['Вес 6 мес']), 'Вес 0 мес']
  - dataset.loc[pd.isna(dataset['% потери веса 6 мес']) & ~pd.isna(dataset['Вес 6 мес']), 'Вес 6 мес'])
  / dataset.loc[pd.isna(dataset['% потери веса 6 мес']) & ~pd.isna(dataset['Вес 6 мес']), 'Вес 0 мес'] * 100, 1
)
dataset.loc[~pd.isna(dataset['% потери веса 6 мес']) & pd.isna(dataset['Вес 6 мес']), 'Вес 6 мес'] = round (
 dataset.loc[~pd.isna(dataset['% потери веса 6 мес']) & pd.isna(dataset['Вес 6 мес']), '% потери веса 6 мес']
 *dataset.loc[~pd.isna(dataset['% потери веса 6 мес']) & pd.isna(dataset['Вес 6 мес']), 'Вес 0 мес'] /100, 1
)

# dataset[dataset["ИМТ 0 мес"].isna()] = (dataset[dataset["ИМТ 0 мес"].isna()]["Вес 0 мес"] / dataset[dataset["ИМТ 0 мес"].isna()]["Рост"]**2).round()

negative_target = ~pd.isna(dataset['% потери веса 3 мес']) \
            & ~pd.isna(dataset['Вес 3 мес']) \
            & (dataset['% потери веса 3 мес'] > 0) \
            & ((dataset['Вес 0 мес']-dataset['Вес 3 мес'])<=0)
dataset.loc[negative_target, '% потери веса 3 мес'] = 0# когда вес увеличился почему то в таблице положительные значения, здесь меняю на противополжое


dataset = dataset.loc[~pd.isna(dataset['Вес 3 мес']) | ~pd.isna(dataset['Вес 6 мес'])]

"""## Target variable"""

dataset["% потери веса 3 мес"].plot.hist()

dataset["success"] = (dataset["% потери веса 3 мес"]>=5).astype(int)
dataset["s0more"] = (dataset["% потери веса 3 мес"]>0).astype(int)

dataset["s0more"].value_counts().plot.bar()

dataset["success"].value_counts().plot.bar()

"""## Анализ распределения колонок"""

dataset["success"] = (dataset["% потери веса 3 мес"]>=5).astype(int)

for c in dataset.columns:
  print(dataset[c].value_counts())
  print("\n")

"""### САД и ДАД и пульс"""

cols = ["ДАД", "Пульс", "САД"]

fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 7))
X_a = dataset["ДАД"]
y = dataset["% потери веса 3 мес"]
X_b = dataset["САД"]
X_c = dataset["Пульс"]
ax[0, 0].scatter(X_a, y)
ax[0, 0].set_title("ДАД к %")
ax[0, 1].scatter(X_b, y)
ax[0, 1].set_title("CАД к %")
ax[1, 0].scatter(X_c, y)
ax[1, 0].set_title("Пульс к %")
ax[1, 1].scatter(X_a, X_b)
ax[1, 1].set_title("САД к ДАД")

X = dataset["ДАД"]
y = dataset["САД"]
cmap = dataset["% потери веса 3 мес"].astype(int).values
fig, ax = plt.subplots(figsize=(10, 5))
scatter = ax.scatter(X, y, c=cmap)
legend1 = ax.legend(*scatter.legend_elements(),loc="lower right", title="Classes")
ax.add_artist(legend1)

X = dataset["ДАД"]
y = dataset["САД"]
rr = dataset["Артериальная гипертензия"].fillna(0).astype(int).values
fig, ax = plt.subplots(figsize=(10, 5))
scatter = ax.scatter(X, y, c=rr)
legend1 = ax.legend(*scatter.legend_elements(),loc="lower right", title="Classes")
ax.add_artist(legend1)

X = dataset["Артериальная гипертензия"]
y = dataset["% потери веса 3 мес"]
plt.scatter(X, y)

"""Видна некая зависимость между САД\ДАД и Артериальной гипертензией. Процент похудения не сильно зависит от нее и давления. Нужно проверить еще статистически, но на первый взгляд можно выбросить САД\ДАД или заменить дискретным признаком. Пульс точно выбросить"""

dataset["СДАД_"] = pd.qcut(dataset["САД"]-dataset["ДАД"], 3, labels=["low", "medium", "high"])
A = dataset.groupby(["СДАД_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("СДАД_", 1)

dataset["Пульс_"] = pd.qcut(dataset["Пульс"], 3, labels=["low", "medium", "high"])
A = dataset.groupby(["Пульс_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Пульс_", 1)

A = dataset.groupby(["Артериальная гипертензия", "success"]).size().unstack()
display(A)
chi2_contingency(A)

"""### EQ-5 Депрессия и Тревога"""

cols = ["EQ-5", "Депрессия", "Тревога"]

fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(14, 7))
X_a = dataset["EQ-5"]
y = dataset["% потери веса 3 мес"]
X_b = dataset["Депрессия"]
X_c = dataset["Тревога"]
ax[0, 0].scatter(X_a, y)
ax[0, 0].set_title("EQ-5 к %")
ax[0, 1].scatter(X_b, y)
ax[0, 1].set_title("Депрессия к %")
ax[0, 2].scatter(X_c, y)
ax[0, 2].set_title("Тревога к %")
ax[1, 0].scatter(X_b, X_c)
ax[1, 0].set_title("Депрессия к Тревога")
ax[1, 1].scatter(X_a, X_c)
ax[1, 1].set_title("EQ-5 к Тревога")
ax[1, 2].scatter(X_a, X_b)
ax[1, 2].set_title("EQ-5 к Депрессия")

X = dataset["Депрессия"]
y = dataset["Тревога"]
cmap = dataset["% потери веса 3 мес"].astype(int).values>=5
fig, ax = plt.subplots(figsize=(10, 5))
scatter = ax.scatter(X, y, c=cmap)
legend1 = ax.legend(*scatter.legend_elements(),loc="lower right", title="Classes")
ax.add_artist(legend1)
ax.set_xlabel('Депрессия')
ax.set_ylabel('Тревога')
ax.set_title("Отношение депрессии к тревоге и успех лечения")

"""Выраженной зависимости от депрессии нет. Есть неявная зависимость, свидетельствующая о том, что у пациентов, кто поставил уровень депрессии больше 4, более успешное лечение"""

(dataset["% потери веса 3 мес"]<5).value_counts()

(dataset["% потери веса 3 мес"]>0).value_counts()

"""Тут я заметил, что если мы берем процент, по которому отсекаем успешных и не успешных пациентов, 5% от начального веса, то пациентов неуспешных больше, чем успешных. Факт, который нужно будет учесть при работе с классификацией и таргетом в качестве дискретного"""

dataset["Депрессия_"] = pd.qcut(dataset["Депрессия"], 2, labels=["no", "yes"])
A = dataset.groupby(["Депрессия_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))
dataset = dataset.drop("Депрессия_", 1)

dataset["Депрессия_"] = pd.qcut(dataset["Депрессия"], 3, labels=["low", "medium", "high"])
A = dataset.groupby(["Депрессия_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Депрессия_", 1)

dataset["Депрессия_"] = pd.qcut(dataset["Депрессия"], 5, labels=["no", "low", "medium", "high", "extra high"])
A = dataset.groupby(["Депрессия_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Депрессия_", 1)

dataset["Тревога_"] = pd.qcut(dataset["Тревога"], 2, labels=["no", "yes"])
A = dataset.groupby(["Тревога_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))
dataset = dataset.drop("Тревога_", 1)

dataset["Депрессия_"] = pd.qcut(dataset["Депрессия"], 2, labels=["low",  "high"])
A = dataset.groupby(["Депрессия_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))
dataset = dataset.drop("Депрессия_", 1)

"""Для сравнения - уровень депрессии через 6 месяцев в зависимости от лечения:"""

full_dataset["6success"] = (full_dataset["% потери веса 6 мес"]>=5).astype(int)
full_dataset["Пульс_"] = pd.qcut(full_dataset["Депрессия В1..1"], 2, labels=["low", "high"])
A = full_dataset.groupby(["Пульс_", "6success"]).size().unstack()
display(A)
display(barnard_exact(A))
full_dataset = full_dataset.drop("Пульс_", 1)

dataset["EQ-5_"] = pd.qcut(dataset["EQ-5"], 3, labels=["low", "medium", "very high"])
A = dataset.groupby(["EQ-5_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("EQ-5_", 1)

dataset["EQ-5_"] = pd.qcut(dataset["EQ-5"], 2, labels=["low", "high"])
A = dataset.groupby(["EQ-5_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))
dataset = dataset.drop("EQ-5_", 1)

"""Депрессия и тревога не сказались на результате лечения. Есть вероятность, что пациенты, указавшие высокое качество жизни, добиваются худших результатов, а те, кто указали низкое качество, их результаты зависят от других параметров(p-value - 0.14)

### Возраст Пол Вес
"""

cols = ["Рост", "Пол", "Возраст", "ИМТ 0 мес", "Вес 0 мес", "ОТ/ОБ 0 мес"]

fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(14, 7))
X_a = dataset["ИМТ 0 мес"]
X_b = dataset["Вес 0 мес"]
X_c = dataset["Возраст"]
X_d = dataset["Пол"]
X_f = dataset["ОТ/ОБ 0 мес"]
X_e = dataset["ОТ 0 мес"]
y = dataset["% потери веса 3 мес"]
ax[0, 0].scatter(X_a, y)
ax[0, 0].set_title("ИМТ к %")
ax[0, 1].scatter(X_b, y)
ax[0, 1].set_title("Вес к %")
ax[0, 2].scatter(X_c, y)
ax[0, 2].set_title("Рост к %")
ax[1, 0].scatter(X_d, y)
ax[1, 0].set_title("Пол (0-М 1-Ж) к %")
ax[1, 1].scatter(X_f, y)
ax[1, 1].set_title("ОТ/ОБ к %")
ax[1, 2].scatter(X_e, y)
ax[1, 2].set_title("ОТ к %")

plt.scatter(X_a, X_e)

dataset["Возраст_"] = pd.qcut(dataset["Возраст"], 2)
A = dataset.groupby(["Возраст_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))

dataset["Возраст_"] = pd.qcut(dataset["Возраст"], 5)
A = dataset.groupby(["Возраст_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))

A = dataset.groupby(["Пол", "success"]).size().unstack()
display(A)
barnard_exact(A)

"""Можно выделить такие утверждения:

1.   С возрастом тяжелее худеть (p-value 0.53)
2.   Женщинам тяжелее снижать вес (p-value 0.36)

### Степень и стаж ожирения
"""

cols = ["Фенотип ожирения", "Степень ожирения", "Стаж ожирения"]

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(14, 7))
X_a = dataset["Степень ожирения"]
X_b = dataset["Вес 0 мес"]
X_c = dataset["ИМТ 0 мес"]
X_d = dataset["Пол"]
X_f = dataset["ОТ/ОБ 0 мес"]
X_e = dataset["ОТ 0 мес"]
y = dataset["% потери веса 3 мес"]
ax[0].scatter(X_a, y)
ax[0].set_title("Степень ожирения к %")
ax[1].scatter(X_b, X_a)
ax[1].set_title("Вес к степени ожирения")
ax[2].scatter(X_c, X_a)
ax[2].set_title("ИМТ к степени ожирения")

print("Spearman between ", "Степень ожирения -", "ИМТ", spearmanr(dataset["Степень ожирения"].fillna(dataset["Степень ожирения"].mean()), dataset["ИМТ 0 мес"].fillna(dataset["ИМТ 0 мес"].mean())))

dataset["success"] = (dataset["% потери веса 3 мес"]>=5).astype(int)
B = dataset.pivot_table(columns = "Фенотип ожирения", index="Стаж ожирения", values = "success", aggfunc="sum")
display(B)
display(chi2_contingency(B))

# A = dataset.pivot_table(columns = "Степень ожирения", index="Стаж ожирения", values = "success", aggfunc="sum")
B = dataset.pivot_table(columns = "Степень ожирения", index="Стаж ожирения", values = "success", aggfunc="size")
display("Стаж:Степень")
B

A = dataset.pivot_table(columns = "Степень ожирения", index="Стаж ожирения", values = "success", aggfunc="sum")
display("Стаж\Степень : успех лечения")
chi2_contingency(A)

print("Spearman between ", "Степень ожирения -", "Стаж ожирения:", spearmanr(dataset["Степень ожирения"], dataset["Стаж ожирения"]))

"""Очень важна связка - стаж+степень ожирения, потому что есть люди которые быстро набрали 3 степень меньше чем за 5 лет, которые возможно получили это из-за нарушения гормонов, а есть которые десятилетиями пришли к такому плохому результату"""

A = dataset.groupby(["Стаж ожирения", "success"]).size().unstack()
display(A)
chi2_contingency(A)

A = dataset.groupby(["Фенотип ожирения", "success"]).size().unstack()
display(A)
chi2_contingency(A)

A = dataset.groupby(["Степень ожирения", "success"]).size().unstack()
display(A)
chi2_contingency(A)

"""Из этой pivot таблицы видно, что стаж ожирения сильно влияет на результат работы модели - при стаже больше 10 лет шанс успешного лечения снижается (p-value 0.1). Так же важна связка стаж+степень ожирения. А вот фенотип не влияет на таргет - его можно исключить

### Опросники пищевого поведения
"""

cols = ["Сытость", "Голод", "Степень желания поесть", "Экстернальное ПП", "Диетическое ПП", "Сколько может сьесть", "Эмоциональное ПП"]

pd.qcut(dataset["Сытость"], 3, labels=["low", "medium", "high"]).value_counts()

dataset["Сытость_"] = pd.qcut(dataset["Сытость"], 3, labels=["low", "medium", "high"])
A = dataset.groupby(["Сытость_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Сытость_", 1)

print("Spearman between ", "Сытость -", "Голод:", spearmanr(dataset["Сытость"], dataset["Голод"]))
print("Spearman between ", "Сытость -", "Голод:", pearsonr(dataset["Сытость"], dataset["Голод"]))

"""Сытость и голод коррелируют и на таргет существенно не влияют - можно убрать"""

print("Spearman between ", "Степень желания поесть -", "Голод:", spearmanr(dataset["Степень желания поесть"], dataset["Голод"]))
print("Pearson between ", "Степень желания поесть -", "Голод:", pearsonr(dataset["Степень желания поесть"], dataset["Голод"]))

dataset["Голод_"] = pd.qcut(dataset["Голод"],  2, labels=["low", "medium"])
A = dataset.groupby(["Голод_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))
dataset = dataset.drop("Голод_", 1)

dataset["Голод_"] = pd.qcut(dataset["Голод"],  3, labels=["low", "medium", "high"])
A = dataset.groupby(["Голод_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Голод_", 1)

dataset["Степень желания поесть_"] = pd.qcut(dataset["Степень желания поесть"], 3, labels=["low", "medium", "high"])
A = dataset.groupby(["Степень желания поесть_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))

dataset["Сколько может сьесть_"] = pd.qcut(dataset["Сколько может сьесть"], 4, labels=["low", "medium", "high", "extra high"])
A = dataset.groupby(["Сколько может сьесть_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Сколько может сьесть_", 1)

"""Здесь с оговоркой на p-value 0.16 можно выделить значимость параметра "Степень желания поесть", а сытость и голод отбрасываем"""

dataset["Эмоциональное ПП_"] = pd.qcut(dataset["Эмоциональное ПП"],  2, labels=["no", "yes"])
A = dataset.groupby(["Эмоциональное ПП_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))
dataset = dataset.drop("Эмоциональное ПП_", 1)

dataset["Эмоциональное ПП_"] = pd.qcut(dataset["Эмоциональное ПП"],  3, labels=["low", "medium", "high"])
A = dataset.groupby(["Эмоциональное ПП_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Эмоциональное ПП_", 1)

dataset["Экстернальное ПП_"] = pd.qcut(dataset["Экстернальное ПП"],  2, labels=["no", "yes"])
A = dataset.groupby(["Экстернальное ПП_", "success"]).size().unstack()
display(A)
display(barnard_exact(A))
dataset = dataset.drop("Экстернальное ПП_", 1)

dataset["Экстернальное ПП_"] = pd.qcut(dataset["Экстернальное ПП"],  3, labels=["low", "medium", "high"])
A = dataset.groupby(["Экстернальное ПП_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))
dataset = dataset.drop("Экстернальное ПП_", 1)

dataset["Диетическое ПП_"] = pd.qcut(dataset["Диетическое ПП"],  4, labels=["no", "low", "medium", "high"])
A = dataset.groupby(["Диетическое ПП_", "success"]).size().unstack()
display(A)
display(chi2_contingency(A))

"""C p-value 0.09 можно утверждать, что строгое Диетическое пищевое поведение в прошлом сильно влияет на результат

### Дискретные лабораторные анализы
"""

cols = ["Дислипидемия", "Артериальная гипертензия", "МЗО/МНО_V3", "НТГ"]

A = dataset.groupby(["Дислипидемия", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["Артериальная гипертензия", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["МЗО/МНО_V3", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["НТГ", "success"]).size().unstack()
display(A)
barnard_exact(A)

"""### Непрерывные лабораторные параметры"""

cols = ["Глюкоза", "ЛПНП", "Инсулин", "ЛПВП", "HOMA-IR", "КА", "СРБ", "HOMA-B", "Мочевая Кислота", "OXC"]

dataset["Глюкоза_"] = dataset["Глюкоза"].apply(lambda x: "low" if x < 3.3 else ("norm" if x < 6.1 else "high"))
dataset["Инсулин_"] = dataset["Инсулин"].apply(lambda x: "low" if x < 17.8 else ("norm" if x < 173 else "high"))
dataset["HOMA-IR_"] = dataset["HOMA-IR"].apply(lambda x: "norm" if x > 3 else "low")
dataset["HOMA-B_"] = dataset["HOMA-B"].apply(lambda x: "norm" if x > 3 else "low")
dataset["Мочевая Кислота_"] = dataset["Мочевая Кислота"].apply(lambda x: "low" if x < 0.14 else ("norm" if x < 0.34 else "high"))
dataset["ЛПВП_"] = dataset["ЛПВП"].apply(lambda x: "norm" if x > 1.1 else "low")
dataset["ЛПНП_"] = dataset["ЛПНП"].apply(lambda x: "norm" if x < 3 else "high")
dataset["КА_"] = dataset["КА"].apply(lambda x: "norm" if x < 3.5 else "high")
dataset["СРБ_"] = dataset["СРБ"].apply(lambda x: "low" "norm" if x < 6 else "high")
dataset["ТГ_"] = dataset["ТГ"].apply(lambda x: "norm" if x < 1.77 else "high")

A = dataset.groupby([ "Инсулин_", "Глюкоза_", "success"]).size().unstack()
display(A)
chi2_contingency(A)

A = dataset.groupby(["Глюкоза_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["Инсулин_", "success"]).size().unstack()
display(A)
barnard_exact(A)

B = dataset.pivot_table(columns = "Инсулин_", index="Глюкоза_", values="success", aggfunc="size")
display(B)
display(barnard_exact(B))

spearmanr(dataset["Инсулин"].fillna(dataset["Инсулин"].mean()), dataset["Глюкоза"].fillna(dataset["Глюкоза"].mean()))

A = dataset.groupby(["HOMA-IR_", "success"]).size().unstack()
display(A)
barnard_exact(A)

dataset["HOMA-B_"] = pd.qcut(dataset["HOMA-B"].fillna(dataset["HOMA-B"].mean()), 2, ["low", "high"])
A = dataset.groupby(["HOMA-B_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["Мочевая Кислота_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["Мочевая Кислота_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["ЛПВП_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["ЛПНП_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["КА_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["СРБ_", "success"]).size().unstack()
display(A)
barnard_exact(A)

A = dataset.groupby(["ТГ_", "success"]).size().unstack()
display(A)
barnard_exact(A)

"""*   ЛПНП
*   КА
*

### Результат
В результате хи-квадрат теста получили следующие параметры
"""

discret_checked_params = [
    'ЛПНП_',
    'Инсулин_',
    'HOMA-IR_',
    'КА_',
    "НТГ",
    "Дислипидемия",
    "Степень желания поесть_",
    "Диетическое ПП_",
    "Стаж ожирения",
    "Степень ожирения", #?
    "Возраст_",
    "Пол"
]

checked_params = [
    'ЛПНП',
    'Инсулин',
    "HOMA-IR",
    "КА",
    "НТГ",
    "Дислипидемия",
    "Стаж ожирения",
    "Степень желания поесть",
    "Диетическое ПП",
    "Степень ожирения",
    "Возраст",
    "Пол"
]

target_discret = "success"

discret_checked_params

from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import classification_report
model = DecisionTreeClassifier()
X = dataset[discret_checked_params]
y = dataset[target_discret]
encoder = OrdinalEncoder().fit(X[discret_checked_params])
X[discret_checked_params] = encoder.transform(X[discret_checked_params])
imputer = SimpleImputer().fit(X)
X.loc[:, :] = imputer.transform(X)
X, X_test, y, y_test = train_test_split(X, y, test_size=0.2)
model.fit(X, y)
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from graphviz import Source
from sklearn import tree
Source(tree.export_graphviz(model, out_file=None, feature_names=X.columns, max_depth=5))

X = dataset[checked_params]
y = dataset[target_discret].astype(int)
imputer = SimpleImputer().fit(X)
X.loc[:, :] = imputer.transform(X)
X, X_test, y, y_test = train_test_split(X, y, test_size=0.2)
model.fit(X, y)
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from graphviz import Source
from sklearn import tree
Source(tree.export_graphviz(model, out_file=None, feature_names=X.columns, class_names=True, max_depth=5))

discret_checked_params[2]

dataset_discret = dataset[discret_checked_params]
dataset = dataset.drop(['ЛПНП_',
 'Инсулин_',
 'HOMA-IR_',
 'КА_',
 'Степень желания поесть_',
 'Диетическое ПП_',
 'Возраст_'], 1)

"""# Графики"""

all_3month = dataset[~pd.isna(dataset["Вес 3 мес"])].shape[0]
all_6month = dataset[~pd.isna(dataset["Вес 6 мес"])].shape[0]
success_3month = dataset[ ~pd.isna(dataset["Вес 3 мес"]) & (dataset["Вес 0 мес"] > dataset["Вес 3 мес"])].shape[0]
success_6month = dataset[ ~pd.isna(dataset["Вес 6 мес"]) & (dataset["Вес 0 мес"] > dataset["Вес 6 мес"])].shape[0]
fail_3month = dataset[ ~pd.isna(dataset["Вес 3 мес"]) & (dataset["Вес 0 мес"] <= dataset["Вес 3 мес"])].shape[0]
fail_6month = dataset[ ~pd.isna(dataset["Вес 6 мес"]) & (dataset["Вес 0 мес"] <= dataset["Вес 6 мес"])].shape[0]
vals = [success_3month/all_3month, fail_3month/all_3month, success_6month/all_6month, fail_6month/all_6month]
plt.figure(figsize=(8, 4))
ax = plt.bar(x = ["3 months - success", "3 months - fail", "6 months - success", "6 months - fail"], height = vals, color=['g', 'r', 'g', 'r'])
rects = ax.patches

for rect, label in zip(rects, vals):
    label = str(label*100)[:4]+"%"
    height = rect.get_height()
    plt.text(
        rect.get_x() + rect.get_width() / 2, height, label, ha="center", va="bottom"
    )
plt.title("Процент успешных случаев за 3 и 6 месяцев терапии")
plt.show()

success_patients_dataset = dataset[
    (~pd.isna(dataset['Вес 6 мес']) & (dataset['Вес 6 мес'] < dataset["Вес 0 мес"]))\
    | (pd.isna(dataset['Вес 6 мес']) & ~pd.isna(dataset['Вес 3 мес']) & (dataset['Вес 3 мес'] < dataset["Вес 0 мес"]))
]
fail_patients_dataset = dataset[
    (~pd.isna(dataset['Вес 6 мес']) & (dataset['Вес 6 мес'] >= dataset["Вес 0 мес"]))\
    | (pd.isna(dataset['Вес 6 мес']) & ~pd.isna(dataset['Вес 3 мес']) & (dataset['Вес 3 мес'] >= dataset["Вес 0 мес"]))
]
plt.figure(figsize=(3, 3))
plt.pie([success_patients_dataset.shape[0], fail_patients_dataset.shape[0]], colors=['g', 'r'], labels=["успешное лечение", "безуспешное лечение"], autopct='%1.1f%%')
plt.title("Процент успешных случаев излечения за 3 или 6 месяцев")
plt.show()

plt.figure(figsize=(3, 3))
dataset["Лечение"].value_counts().plot.pie(autopct='%1.1f%%')
plt.title("Используемое лечение")

"""Посмторим на разложение tSNE"""

from sklearn.preprocessing import OrdinalEncoder
parameters.append("Пол")
pl = parameters.copy()
pl = [pl[i] for i in [0, 1, 2, 3, 7, 8, 14, 15, 16, 17, 18]]
enc_x = dataset[pl].copy()
enc_x.iloc[:, 0] = OrdinalEncoder().fit_transform(dataset[pl].iloc[:, 0:1])
enc_x = SimpleImputer().fit_transform(enc_x)
transformer = TSNE(
    n_components=2,
    n_iter=1000,
    n_iter_without_progress=150,
    n_jobs=-1,
)
tsne_X = transformer.fit_transform(enc_x)
plt.figure(figsize=(10, 10))
for i, m in list(zip([0, 1, 2], ["*", "o", "P"])):
  plt.scatter(tsne_X[enc_x[:, 0]==i, 0], tsne_X[enc_x[:, 0]==i, 1], c=(dataset.loc[enc_x[:, 0]==i, "% потери веса 3 мес"]>1).astype(np.int64), marker=m, cmap="tab10", s=50)

"""Примерно можно сказать, что на краях этой области находятся сэмплы с безуспешным результатом, но это совсем не точно

Представим в целом результаты лечения:
"""

fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(14, 16))
for i in range(3):
  med = ["SIB", "STD", "SAX"][i]
  data = dataset[dataset["Лечение"]==med]
  axs[i][0].bar(height=data["% потери веса 3 мес"]+0.1, x=data.index, color=(data["% потери веса 3 мес"]>0).replace({True: 'g', False: 'r'}))
  axs[i][0].set_ylabel("% потери веса 3 мес")
  axs[i][0].set_title(f"Результаты лечения методом {medicines[med]} в 3 мес по пациентам")
  axs[i][1].pie((data["% потери веса 3 мес"]>0).value_counts(), autopct="%1.1f%%", labels = ["% изменения веса > 0", "% изменения веса <= 0"], colors=["g", "r"])
plt.show()

"""# Feature engineering

Выбираем дискретные параметры

### Тест Колмогорова-Смирнова для непрерывных величин

Проводит тест Колмогорова-Смирнова для непрерывных величин чтобы понять, различается ли распределение непрерывных величин при удачном и неудачном лечении Сибутрамином
"""

list(filter(lambda x: x not in discret_params+["Лечение"]+targets, agroup_parameters))

from scipy.stats import ks_2samp
target = "% потери веса 3 мес"
params = list(filter(lambda x: x not in discret_params+["Лечение"]+targets, agroup_parameters)) # берем только непрерывные предикторы
agroup_dataset = dataset[params]
fail_dataset = agroup_dataset[dataset[target]<5]
succ_dataset = agroup_dataset[dataset[target]>=5]
stats = []
for p in params:
  param_from_fail = fail_dataset[p]
  param_from_succ = succ_dataset[p]
  ks_result = ks_2samp(param_from_fail, param_from_succ)
  stats.append([p, ks_result[0], ks_result[1], "различается" if ks_result[1]<0.05 else "не различается"])
ks_stats = pd.DataFrame(stats, columns=["Параметр", "KS-test value", "KS-test p_value", "Различаются распределения?"]).round(2)
ks_stats = ks_stats[ks_stats["Параметр"]!=target].sort_values("KS-test p_value", ascending=True)
display("SIB KS test success/fail")
display(ks_stats)

"""С веротяностью 83% КА (плохой\хороший холестерин) строится по такому же распределению, как и процент потери веса
С веротяностью 76% ЛПВП строится по такому же распределению, как и процент потери веса
"""



"""### Корреляции Спирмана и Пирсона между параметрами и таргетом"""

from scipy import stats
def pearsonr_test(target="% потери веса 3 мес", params=list(filter(lambda x: x not in discret_params+["Лечение"]+targets, agroup_parameters)), medicine='SIB'):
  params = list(set(params))
  if (medicine==None):
    x = dataset[params]
    y = dataset[target]
  else:
    x = dataset[dataset["Лечение"]==medicine][params]
    y = dataset[dataset["Лечение"]==medicine][target]
  x.loc[:, :] = SimpleImputer().fit_transform(x)
  y.loc[:] = SimpleImputer().fit_transform(y.to_numpy().reshape(-1, 1)).reshape(-1)
  f = []
  for p in params:
    res = spearmanr(np.array(x[p]), y)
    f.append([p, res.pvalue, res.correlation])
  return pd.DataFrame(f, columns=["Parameter", "p-value", "pearsonr"])

default_params = list(filter(lambda x: x not in discret_params+["Лечение"]+targets, agroup_parameters))
def spearman_test(target="% потери веса 3 мес", params = default_params, medicine='SIB'):
  params = list(set(params))
  if (medicine==None):
    x = dataset[params]
    y = dataset[target]
  else:
    x = dataset[dataset["Лечение"]==medicine][params]
    y = dataset[dataset["Лечение"]==medicine][target]
  x.loc[:, :] = SimpleImputer().fit_transform(x)
  y.loc[:] = SimpleImputer().fit_transform(y.to_numpy().reshape(-1, 1)).reshape(-1)
  f = []
  for p in params:
    res = spearmanr(np.array(x[p]), y)
    f.append([p, res.pvalue, res.correlation])
  return pd.DataFrame(f, columns=["Parameter", "p-value", "spearmanr"])

spearman_test(target="% потери веса 3 мес").sort_values(by="p-value", ascending=False)

spearman_test(target="% потери веса 3 мес", medicine=None).sort_values(by="p-value", ascending=False)

spearman_test(target="Вес 3 мес")

spearman_test(target="Вес 3 мес")

"""А если в качестве второй переменной взять Вес в начале, то мы увидим строгую корреляцию между некоторыми переменными и начальным весом, и эти переменные могут напрямую не влиять на таргет (% изменения жира), а только являются причиной повышенного веса"""

spearman_test(target="Вес 0 мес")

spearman_test(target="Вес 0 мес")

"""### Корреляция между колонками датасета

Корреляция между колонками - метод ранговой корреляции Спирмана
"""

target_col = "% потери веса 3 мес"
matrix_spearmanr_pvalue = spearman_test(target=target_col, medicine=None)
matrix_spearmanr_pvalue[target_col] = matrix_spearmanr_pvalue["p-value"]
matrix_spearmanr = spearman_test(target=target_col, medicine=None)
matrix_spearmanr[target_col] = matrix_spearmanr["spearmanr"]
for i in params:
  res = spearman_test(target=i, medicine=None)
  matrix_spearmanr[i] = res[res["p-value"]<0.05]["spearmanr"]
matrix_spearmanr = matrix_spearmanr.drop(columns=["p-value", "spearmanr"])
matrix_spearmanr.fillna("---")

target_col = "% потери веса 3 мес"
matrix_pearsonr_pvalue = pearsonr_test(target=target_col, medicine=None)
matrix_pearsonr_pvalue[target_col] = matrix_pearsonr_pvalue["p-value"]
matrix_pearsonr = pearsonr_test(target=target_col, medicine=None)
matrix_pearsonr[target_col] = matrix_pearsonr["pearsonr"]
for i in params:
  res = pearsonr_test(target=i, medicine=None)
  matrix_pearsonr[i] = res[res["p-value"]<0.05]["pearsonr"]
matrix_pearsonr = matrix_pearsonr.drop(columns=["p-value", "pearsonr"])
matrix_pearsonr.fillna("-")

target_col = "% потери веса 3 мес"
all_params = [target_col]+list(filter(lambda x: x not in ["Лечение"], agroup_parameters))
res = spearman_test(target=target_col, medicine=None, params=all_params)
matrix_spearmanr = res
for i in all_params:
  res = spearman_test(target=i, medicine=None, params=all_params)
  matrix_spearmanr[i] = res[res["p-value"]<0.05]["spearmanr"]
matrix_spearmanr = matrix_spearmanr.drop(columns=["p-value", "spearmanr"])
matrix_spearmanr.fillna("---")

"""Для дискретных параметров проверим различие распределений с помощью хи-квадрат теста

### Хи-квадрат тест
"""

target = "% потери веса 3 мес"
agroup_dataset = dataset[discret_params]
agroup_dataset.fillna(value=agroup_dataset.mean(), inplace=True)
agroup_dataset["success"] = (dataset[target]>0).astype(np.int32)
agroup_dataset["Тревога"] = pd.qcut(agroup_dataset["Тревога"], q=[0, 0.4, 0.8, 1],
                         labels=["lowest", "middle", "top"])
agroup_dataset["Депрессия"] = pd.qcut(agroup_dataset["Депрессия"], q=[0, 0.4, 0.8, 1],
                         labels=["lowest", "middle", "top"])
agroup_dataset["Экстернальное ПП"] = pd.qcut(agroup_dataset["Экстернальное ПП"], q=[0, 0.4, 0.8, 1],
                         labels=["lowest", "middle", "top"])
agroup_dataset["Эмоциональное ПП"] = pd.qcut(agroup_dataset["Эмоциональное ПП"], q=[0, 0.4, 0.8, 1],
                         labels=["lowest", "middle", "top"])
agroup_dataset["Диетическое ПП"] = pd.qcut(agroup_dataset["Диетическое ПП"], q=[0, 0.4, 0.8, 1],
                         labels=["lowest", "middle", "top"])

chisquare([23, 77], [50, 50])

for c in dataset.columns:
  print(dataset[c].value_counts())
  print("\n")

chi2_stats = []
for col in discret_params:
  ptb = agroup_dataset.pivot_table(index=col, columns="success", aggfunc='size', fill_value=0, dropna=False)
  a, b = ptb[0], (ptb[1]/sum(ptb[1]))*sum(ptb[0])
  chi2_stats.append([col, chisquare(a, b)[0], chisquare(a, b)[1]])
pd.DataFrame(chi2_stats, columns=["Параметр", "хи-квадрат", "p-value"])

"""### Mutual info test"""

from sklearn.feature_selection import mutual_info_classif
target = "% потери веса 3 мес"
predictors = list(filter(lambda x: x not in discret_params+["Лечение"]+targets+initial_columns, agroup_parameters))
X = dataset[dataset["Лечение"]=="SIB"][predictors]
y = (dataset[dataset["Лечение"]=="SIB"][target]>5).astype(np.int).to_numpy().squeeze()
importances = mutual_info_classif(X, y)
feature_importances = pd.Series(importances, X.columns)
feature_importances.plot(kind='barh', color='teal')
plt.show()

from sklearn.feature_selection import mutual_info_classif
target = "% потери веса 3 мес"
predictors = list(filter(lambda x: x not in discret_params+["Лечение"]+targets, agroup_parameters))
X = dataset[predictors]
y = (dataset[target]>5).astype(np.int).to_numpy().squeeze()
importances = mutual_info_classif(X, y)
feature_importances = pd.Series(importances, predictors)
feature_importances.plot(kind='barh', color='teal')
plt.show()

from sklearn.feature_selection import mutual_info_classif
target = "% потери веса 3 мес"
predictors = list(filter(lambda x: x not in targets, agroup_parameters))
X = dataset[predictors]
y = (dataset[target]>5).astype(np.int).to_numpy().squeeze()
X["SIB"] = (X["Лечение"]=="SIB").astype(int)
X["STD"] = (X["Лечение"]=="STD").astype(int)
X["SAX"] = (X["Лечение"]=="SAX").astype(int)
X = X.drop(columns="Лечение")
importances = mutual_info_classif(X, y)
feature_importances = pd.Series(importances, X.columns)
feature_importances.plot(kind='barh', color='teal')
plt.show()

"""Посмотрим пропущенные значения"""

tdesc = dataset.describe()
dft = pd.DataFrame(106 - tdesc.T["count"])
dft.index = [j[:20] for j in dft.index]
dft.style.set_caption("Колонки с пропущенными значениями")
pd.set_option('max_colwidth', 120)
pd.options.display.max_rows = 20
dft

dataset = dataset[dataset["Лечение"]=="SIB"] #берем только Сибутрамин
dataset = dataset.drop("Лечение", axis=1) # берем только Сибутрамин
agroup_parameters.remove("Лечение")
parameters.remove("Лечение")

"""# Построение модели

Строить модель будем для Сибутрамина

В функции pipeline мы применяем CV стратегию Leave-One-Out и тестируем модель. Метрики качества - R2, RMSE, MAE
Также мне интересно узнать качество классификации результата лечения.  Для этого я присваиваю 0 всем результатам, где разница в весе меньше килограмма и 1 где разница больше киллограма. И для полуичвшихся векторов считаю accuracy, precision, ROC AUC
"""

from sklearn.metrics import recall_score, precision_score, roc_auc_score

default_predictors = list(filter(lambda x: x not in targets, agroup_parameters)) # список предикторов
def validate_model(pipe_super, dataset, target="% потери веса 3 мес"):
  np.random.seed(42)

  # cv
  cv_loo = LeaveOneOut()
  X = dataset.drop(columns=target)
  y = dataset[target]
  X = X.reset_index(drop=True)
  y = y.reset_index(drop=True)
  y_pred = []
  for idx, (train_index, test_index) in enumerate(cv_loo.split(X)):
    X_train, X_test, y_train, y_test = X.iloc[train_index, :], \
                                      X.iloc[test_index, :], \
                                      y[train_index], \
                                      y[test_index]
    pipe_super.fit(X_train, y_train)
    y_pred.append(pipe_super.predict(X_test))

  model_name = pipe_super["regressor"].__class__.__name__

  # intervals
  y, y_pred = np.array(y).squeeze(), np.array(y_pred).squeeze()
  mse = (y - y_pred) ** 2
  mae = np.abs(y - y_pred)
  r2 = ((y-y_pred)**2)/((y-np.mean(y))**2)
  l_mse, r_mse = norm.interval(0.95, loc=np.mean(mse), scale=np.std(mse))
  l_mae, r_mae = norm.interval(0.95, loc=np.mean(mae), scale=np.std(mae))
  l_r2, r_r2 = norm.interval(0.95, loc=np.mean(r2), scale=np.std(r2))

  # binary metrics
  y_label = (y>5).astype(np.int64).squeeze()
  y_pred_label = (y_pred>5).astype(np.int64).squeeze()

  res= {
      "model": model_name,
      "date": datetime.now().strftime("%H:%M %d/%m/%y"),
      "r2": r2_score(y, y_pred),
      "interval_explained_variance": (l_r2, r_r2),
      "mae": mean_absolute_error(y, y_pred),
      "interval_mae": (round(max(0, l_mae), 2), round(r_mae, 2)),
      "rmse": mean_squared_error(y, y_pred, squared=False),
      "interval_rmse": (round(max(0, np.sqrt(l_mse)), 2), round(np.sqrt(r_mse), 2)),
  }
  try:
    res.update({ "accuracy": accuracy_score(y_label, y_pred_label),
    "precision": precision_score(y_label, y_pred_label),
    "recall": precision_score(y_label, y_pred_label),
    "rocAUC": roc_auc_score(y_label, y_pred_label),
    "f1": f1_score(y_label, y_pred_label)})
  except:
    pass
  return res

def show_stats(stats):
  metrics_df = pd.DataFrame()
  for row in stats:
    metrics_df = metrics_df.append(row, ignore_index=True)
  return metrics_df

"""В эксперименте я использую следующие модели:
 - Linear Regression
 - Random Forest
 - Decision Tree
 - SVR
 - Lasso
 - Gradient Boosting Regressor
"""

list_models = [
    LinearRegression(),
    RandomForestRegressor(),
    DecisionTreeRegressor(),
    SVR(),
    Lasso()
]

metrics_stats = []
target = "% потери веса 3 мес"
for idx, model in enumerate(list_models):
  pipe = Pipeline([
    ("imputer", SimpleImputer()),
    ("regressor", model)
  ])
  metrics_stats.append(validate_model(pipe, dataset[checked_params+[target]], target=target))
show_stats(metrics_stats)

list_models = [
    LinearRegression(),
    RandomForestRegressor(),
    DecisionTreeRegressor(),
    SVR(),
    Lasso()
]

metrics_stats = []
target = "% потери веса 3 мес"
for idx, model in enumerate(list_models):
  pipe = Pipeline([
    ("imputer", SimpleImputer()),
    ("regressor", model)
  ])
  metrics_stats.append(validate_model(pipe, dataset[discret_checked_params+[target]], target=target))
show_stats(metrics_stats)

"""### выбор параметров через поочерендое удаление"""

pscut = [
 'ЛПНП',
 'Глюкоза',
 'EQ-5',
 'Степень ожирения',
 'КА',
 'Диетическое ПП',
 'Экстернальное ПП',
 'HOMA-IR',
 'HOMA-B',
 'НТГ',
 'Артериальная гипертензия',
 'Возраст',
 'Дислипидемия',
 'МЗО/МНО_V3',
 'ЛПВП',
 'СРБ',
 'Фенотип ожирения',
 'OXC',
 'Пол',
 'Мочевая Кислота',
 'Тревога',
 'Эмоциональное ПП',
 'Сколько может сьесть',
 'Инсулин',
 'ТГ',
 'Голод',
 'Депрессия',
 'Стаж ожирения'
]

"""### Пробуем предсказать вес текущий"""

from sklearn.tree import DecisionTreeRegressor
list_models = [
    LinearRegression(),
    RandomForestRegressor(),
    DecisionTreeRegressor(),
    SVR(),
    Lasso()
]

metrics_stats = []
target = "Вес 0 мес"
for idx, model in enumerate(list_models):
  pipe = Pipeline([
    ("imputer", SimpleImputer()),
    ("regressor", model)
  ])
  metrics_stats.append(validate_model(pipe, dataset[pscut+[target]], target=target))
show_stats(metrics_stats)

show_stats(metrics_stats)

from sklearn.tree import DecisionTreeRegressor
list_models = [
    LinearRegression(),
    RandomForestRegressor(),
    DecisionTreeRegressor(),
    SVR(),
    Lasso()
]

metrics_stats = []
target = "Вес 3 мес"
for idx, model in enumerate(list_models):
  pipe = Pipeline([
    ("imputer", SimpleImputer()),
    ("regressor", model)
  ])
  metrics_stats.append(validate_model(pipe, dataset[pscut+[target]], target=target))
show_stats(metrics_stats)

"""### RFECF"""

from sklearn.feature_selection import RFECV
selector = RFECV(RandomForestRegressor(), step=2, cv=5)
predict = pscut
target = "% потери веса 3 мес"
X = dataset[predict]
y = dataset[target]
imputer = SimpleImputer().fit(X)
X.loc[:, :] = imputer.transform(X)
selector = selector.fit(X, y)
np.array(predict)[selector.support_]

t = list(zip(np.array(predict)[selector.support_], selector.ranking_))
t.sort(key=lambda x: x[1])
pd.DataFrame(t, columns=["Параметр", "Ранг"])

"""### Feature Importances"""

pipe = Pipeline([
  ("imputer", SimpleImputer()),
  ("regressor", RandomForestRegressor())
])
predict = pscut
target = "% потери веса 3 мес"
X = dataset[predict]
y = dataset[target]
pipe.fit(X, y)

feature_names = pipe[:-1].get_feature_names_out()
mdi_importances = pd.Series(
    pipe[-1].
    feature_importances_, index=feature_names
).sort_values(ascending=True)
plt.bar(x=feature_names,  height=mdi_importances)
plt.xticks(rotation=90)
plt.show()

result = permutation_importance(
    pipe, X, y, n_repeats=10, random_state=42,)

sorted_importances_idx = result.importances_mean.argsort()
importances = pd.DataFrame(
    result.importances[sorted_importances_idx].T,
    columns=feature_names[sorted_importances_idx],
)

fig, ax = plt.subplots()
ax = plt.boxplot(importances, vert=False, whis=10, labels=importances.columns)

"""# SHAP

Построим модель обьяснения работы модели регрессии
"""

!pip install shap

import shap, graphviz

X = dataset[checked_params]
y = dataset[target]

model = DecisionTreeRegressor()
imputer = SimpleImputer().fit(X)
X.loc[:, :] = imputer.transform(X)
model.fit(X, y)
explainer = shap.TreeExplainer(model, X)
shap_values = explainer(X)

shap.plots.violin(shap_values)

shap.plots.waterfall(shap_values[7])

"""# Fedot"""

import logging

default_predictors = list(filter(lambda x: x not in targets, agroup_parameters)) # список предикторов
def validate_model_fedot(pipe_super, dataset, target="% потери веса 3 мес"):
  target = "% потери веса 3 мес"
  np.random.seed(42)

  # cv
  cv_loo = LeaveOneOut()
  X = dataset.drop(columns=target)
  y = dataset[target]
  y_pred = []
  for idx, (train_index, test_index) in enumerate(cv_loo.split(dataset)):

    X_train, X_test, y_train, y_test = X.iloc[train_index, :], \
                                      X.iloc[test_index, :], \
                                      y[train_index], \
                                      y[test_index]
    data_fedot_train =
    pipe_super.unfit()
    pipe_super.fit(X_train, y_train)
    y_pred.append(pipe_super.predict(X_test))

  # intervals
  y, y_pred = np.array(y).squeeze(), np.array(y_pred).squeeze()
  mse = (y - y_pred) ** 2
  mae = np.abs(y - y_pred)
  r2 = ((y-y_pred)**2)/((y-np.mean(y))**2)
  print(r2)
  l_mse, r_mse = norm.interval(alpha=0.95, loc=np.mean(mse), scale=np.std(mse))
  l_mae, r_mae = norm.interval(alpha=0.95, loc=np.mean(mae), scale=np.std(mae))
  l_r2, r_r2 = norm.interval(alpha=0.95, loc=np.mean(r2), scale=np.std(r2))

  # binary metrics
  y_label = (y>5).astype(np.int64).squeeze()
  y_pred_label = (y_pred>5).astype(np.int64).squeeze()
  try:
    model_name = pipe_super["regressor"].__class__.__name__
  except:
    try:
      model_name = str(pipe_super)
    except:
      model_name = "Undefined"
  return {
      "model": model_name,
      "date": datetime.now().strftime("%H:%M %d/%m/%y"),
      "r2": r2_score(y, y_pred),
      "interval_explained_variance": (l_r2, r_r2),
      "mae": mean_absolute_error(y, y_pred),
      "interval_mae": (round(max(0, l_mae), 2), round(r_mae, 2)),
      "rmse": mean_squared_error(y, y_pred, squared=False),
      "interval_rmse": (round(max(0, np.sqrt(l_mse)), 2), round(np.sqrt(r_mse), 2)),
      "accuracy": accuracy_score(y_label, y_pred_label),
      "precision": precision_score(y_label, y_pred_label),
      "recall": precision_score(y_label, y_pred_label),
      "rocAUC": roc_auc_score(y_label, y_pred_label),
      "f1": f1_score(y_label, y_pred_label)
  }

params = parameters
target = "% потери веса 3 мес"
X = dataset[params].iloc[7:, :]
y = dataset[target].iloc[7:]
fedot_solver = Fedot(problem="regression", timeout=1, preset='fast_train', n_jobs=-1, logging_level=logging.FATAL)
result = fedot_solver.fit(X, y)

validate_model_fedot(result, dataset, target="% потери веса 3 мес")

if fedot_solver.history and fedot_solver.history.generations:
    print(fedot_solver.history.get_leaderboard())

fedot_solver.current_pipeline.show()

X_test = X.iloc[:6, :]
y_test = y[:6]
X_test.drop(columns=[target], inplace=True)
X_test

fedot_solver.predict(X_test)
metrics = fedot_solver.get_metrics()

fedot_solver.predict(X_test)

X_test[target]

metrics